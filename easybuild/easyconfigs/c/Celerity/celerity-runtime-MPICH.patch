patch for celerity-runtime on LUMI for MPICH, specifically to align MPI_DataType
author: Bert Jorissen (University of Antwerp/CalcUA/VSC/EPICURE)
diff -ru celerity-runtime.orig/include/mpi_communicator.h celerity-runtime/include/mpi_communicator.h
--- celerity-runtime.orig/include/mpi_communicator.h
+++ celerity-runtime/include/mpi_communicator.h
@@ -54,6 +54,7 @@ class mpi_communicator final : public communicator {

 	struct datatype_deleter {
 		void operator()(MPI_Datatype dtype) const;
+		void operator()(int* dtype) const;
 	};
 	using unique_datatype = std::unique_ptr<std::remove_pointer_t<MPI_Datatype>, datatype_deleter>;

diff -ru celerity-runtime.orig/src/backend/CMakeLists.txt celerity-runtime/src/backend/CMakeLists.txt
--- celerity-runtime.orig/src/backend/CMakeLists.txt
+++ celerity-runtime/src/backend/CMakeLists.txt
@@ -8,7 +8,7 @@ if(NOT CELERITY_SYCL_IMPL STREQUAL "SimSYCL")
     set(CUDA_OR_CUDA_TOOLKIT_FOUND ${CUDA_FOUND})
   endif()
   # find_package(LevelZero QUIET) # TODO: Need find module?
-  # find_package(ROCM QUIET) # TODO: Need find module?
+  find_package(ROCM) # TODO: Need find module?

   option(CELERITY_ENABLE_CUDA_BACKEND "Enable optimized code paths for CUDA backends" ${CUDA_OR_CUDA_TOOLKIT_FOUND})
 else()
@@ -42,4 +42,5 @@ if(CELERITY_ENABLE_CUDA_BACKEND)
   message(STATUS "CUDA backend enabled")
 else()
   target_compile_definitions(celerity_backends PUBLIC "CELERITY_DETAIL_BACKEND_CUDA_ENABLED=0")
+  message(STATUS "NO CUDA backend found")
 endif()
diff -ru celerity-runtime.orig/src/mpi_communicator.cc celerity-runtime/src/mpi_communicator.cc
--- celerity-runtime.orig/src/mpi_communicator.cc
+++ celerity-runtime/src/mpi_communicator.cc
@@ -245,19 +245,19 @@ std::unique_ptr<communicator> mpi_communicator::collective_clone() { return std:
 void mpi_communicator::collective_barrier() { MPI_Barrier(m_mpi_comm); }

 MPI_Datatype mpi_communicator::get_scalar_type(const size_t bytes) {
-	if(const auto it = m_scalar_type_cache.find(bytes); it != m_scalar_type_cache.end()) { return it->second.get(); }
+	if(const auto it = m_scalar_type_cache.find(bytes); it != m_scalar_type_cache.end()) { return *it->second.get(); }

 	assert(bytes > 0);
 	assert(bytes <= static_cast<size_t>(INT_MAX));
 	MPI_Datatype type = MPI_DATATYPE_NULL;
 	MPI_Type_contiguous(static_cast<int>(bytes), MPI_BYTE, &type);
 	MPI_Type_commit(&type);
-	m_scalar_type_cache.emplace(bytes, unique_datatype(type));
+	m_scalar_type_cache.emplace(bytes, unique_datatype(new int(type)));
 	return type;
 }

 MPI_Datatype mpi_communicator::get_array_type(const stride& stride) {
-	if(const auto it = m_array_type_cache.find(stride); it != m_array_type_cache.end()) { return it->second.get(); }
+	if(const auto it = m_array_type_cache.find(stride); it != m_array_type_cache.end()) { return *it->second.get(); }

 	const int dims = detail::get_effective_dims(stride.allocation_range);
 	assert(detail::get_effective_dims(stride.transfer) <= dims);
@@ -284,8 +284,7 @@ MPI_Datatype mpi_communicator::get_array_type(const stride& stride) {
 	MPI_Datatype type = MPI_DATATYPE_NULL;
 	MPI_Type_create_subarray(dims, size_array, subsize_array, start_array, MPI_ORDER_C, get_scalar_type(stride.element_size), &type);
 	MPI_Type_commit(&type);
-
-	m_array_type_cache.emplace(stride, unique_datatype(type));
+	m_array_type_cache.emplace(stride, unique_datatype(new int(type)));
 	return type;
 }

@@ -293,6 +292,16 @@ void mpi_communicator::datatype_deleter::operator()(MPI_Datatype dtype) const {
 	MPI_Type_free(&dtype);
 }

+void mpi_communicator::datatype_deleter::operator()(int* dtype) const {
+    if (dtype != nullptr) {
+        // Dereference the pointer to get the MPI_Datatype value
+        MPI_Type_free(dtype);
+
+        // Free the dynamically allocated pointer
+        delete dtype;
+    }
+}
+
 } // namespace celerity::detail

 namespace celerity::experimental {
diff -ru celerity-runtime.orig/src/runtime.cc celerity-runtime/src/runtime.cc
--- celerity-runtime.orig/src/runtime.cc
+++ celerity-runtime/src/runtime.cc
@@ -254,7 +254,7 @@ namespace detail {
 		// TODO: Assert that shared memory is available (i.e. not explicitly disabled)
 #define SPLIT_TYPE MPI_COMM_TYPE_SHARED
 #endif
-		MPI_Comm host_comm = nullptr;
+		MPI_Comm host_comm = MPI_COMM_NULL;
 		MPI_Comm_split_type(MPI_COMM_WORLD, SPLIT_TYPE, 0, MPI_INFO_NULL, &host_comm);

 		int local_rank = 0;
